#set document(title: "Title", author: "Author", description: "An N-gram Language Model")
#set text(font: "Libertinus Serif", size: 8pt)
#let book_url = "https://www.gutenberg.org/ebooks/84"

// how many sided die will the book be optimised for?
#let dice_d = 120

// Load the JSON data
#let data = json("model.json")

// Create a state variable to track the current prefix
#let current_prefix = state("current-prefix", "")

// Title page function
#let title-page() = {
  set page(margin: (x: 2.5cm, y: 2.5cm))
  align(center + horizon)[
    #v(2cm)
    #text(weight: "bold", size: 2.5em)[#context document.title]
    #v(1cm)
    #text(size: 1.2em)[#context document.description]
    #v(5cm)
    #text(size: 1.2em)[2025]
  ]
  pagebreak()
}

// Copyright page
#let copyright-page() = {
  set page(margin: (x: 2.5cm, y: 2.5cm))
  set text(size: 12pt)
  align(horizon)[
    #text(size: 1.2em)[#context document.description of #context document.title]
    #v(0.7cm)
    #text(size: 1em)[© 2025 Cybernetic Studio]
    #v(0.5cm)
    #text(size: 0.9em)[
      This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0).
    ]
    #v(0.5cm)
    #text(size: 0.9em)[ISBN: 978-0-00000-000-0]
    #v(0.5cm)
    #text(size: 0.9em)[Published by Cybernetic Studio Press]
    #v(0.5cm)
    #text(size: 0.9em)[First Edition]
    #v(0.5cm)
    #text(size: 0.9em, style: "italic")[
      This reference contains a statistical language model derived from text corpus analysis.
      The patterns within represent probabilistic relationships between words and their sequences.
    ]
    #v(0.5cm)
    #text(size: 0.9em)[
      Disclaimer: The patterns and predictions generated by this language model are
      statistical in nature and may not always reflect proper grammar, factual accuracy,
      or appropriate content.
    ]
    #v(0.5cm)
    #text(size: 0.9em)[
      Credits: Software design, implementation and typesetting by Ben Swift for the Cybernetic Studio.

      Based on the text of the book #text(style: "italic")[#context document.title] by #text[#context document.author.first()], available from
      #link(book_url)[Project Gutenberg at #raw(book_url)].
    ]
    #v(0.5cm)
    #text(size: 0.9em)[
      The source code for the tool used to create this model is available under an MIT Licence from
      #link("https://github.com/ANUcybernetics/my-first-lm")[`https://github.com/ANUcybernetics/my-first-lm`]
    ]
  ]
  pagebreak()
}

// Introduction page
#let introduction() = {
  set page(margin: (x: 2.5cm, y: 2.5cm))
  align(left)[
    #heading(level: 1)[Introduction]
    #v(0.5cm)
    This reference contains a statistical n-gram language model that shows the probabilistic
    relationships between word sequences. Each entry displays a prefix followed by possible
    continuations with their associated probabilities.

    The model can be used for text prediction, generation, and analysis of linguistic patterns.

    #v(0.5cm)
    #heading(level: 2)[How to Read This Reference]
    Each entry contains:
    - A bold prefix sequence
    - A diamond symbol (♢) followed by a number indicating the total occurrence count (only when not equal to 120)
    - Possible continuations with their occurrence counts
  ]
  pagebreak()
}

// Table of contents
#let table-of-contents() = {
  set page(margin: (x: 2.5cm, y: 2.5cm))
  heading(level: 1)[Contents]
  v(1cm)
  // A simple table of contents would be difficult to generate for all prefixes
  // For a real book, you might want to generate sections based on first letters or similar
  [The following pages contain all n-gram sequences organized alphabetically by prefix.]
  pagebreak()
}

// Generate front matter
#title-page()
#copyright-page()
// #introduction()
// #table-of-contents()

// Main content with original layout
#set page(
  "a4",
  margin: (x: 1.5cm, y: 1.5cm),
  columns: 4,
  numbering: "1/1"
  // header: {
  //   set align(left)
  //   text(weight: "bold")[#context current_prefix.at(here())]
  //   line(length: 100%, stroke: 0.5pt + luma(50%))
  // }
)

#for (i, item) in data.enumerate() {
  // The first element is the prefix
  let prefix = item.at(0)
  let total_count = item.at(1)
  let followers = item.slice(2)
  current_prefix.update(prefix)

  // this is the prefix text with a label
  [#text(prefix, size: 1.3em, weight: "bold")#label("prefix-" + prefix)]

  // the dice roll number
  if total_count != dice_d {
    h(0.3em)
    [(#box[#text(weight: "bold")[#str(total_count).len()]♢])]
  }

  h(0.6em)

  // the followers for this prefix (with weights)
  for follower in followers {
    if followers.len() > 1 {
      box([#text[#follower.at(1)]|#text[#follower.at(0)]])
    } else {
      box([#follower.at(0)])
    }
    h(0.5em)
  }

  v(0.1em)
}
